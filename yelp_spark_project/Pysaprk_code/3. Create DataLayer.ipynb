{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5a8798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession.Builder at 0x7f0ff1585af0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"pj2-project\").getOrCreate()\n",
    "\n",
    "# https://sparkbyexamples.com/apache-hive/pyspark-save-dataframe-to-hive-table/\n",
    "SparkSession.builder.enableHiveSupport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a186add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "23/03/13 00:48:18 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df_business = spark.read.table(\"yelp.business\")\n",
    "df_tip = spark.read.table(\"yelp.tip\")\n",
    "df_checkin = spark.read.table(\"yelp.checkin\")\n",
    "df_user = spark.read.table(\"yelp.user\")\n",
    "df_review = spark.read.table(\"yelp.review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e370d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = [df_review, df_user,df_checkin, df_tip, df_business]\n",
    "table_list_str = ['df_review', 'df_user','df_checkin', 'df_tip', 'df_business']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35b2fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_col_list= [set(i.columns) for i in table_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "795b63f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'business_id',\n",
       "  'cool',\n",
       "  'date',\n",
       "  'funny',\n",
       "  'review_id',\n",
       "  'stars',\n",
       "  'text',\n",
       "  'useful',\n",
       "  'user_id'},\n",
       " {'average_stars',\n",
       "  'compliment_cool',\n",
       "  'compliment_cute',\n",
       "  'compliment_funny',\n",
       "  'compliment_hot',\n",
       "  'compliment_list',\n",
       "  'compliment_more',\n",
       "  'compliment_note',\n",
       "  'compliment_photos',\n",
       "  'compliment_plain',\n",
       "  'compliment_profile',\n",
       "  'compliment_writer',\n",
       "  'cool',\n",
       "  'elite',\n",
       "  'fans',\n",
       "  'friends',\n",
       "  'funny',\n",
       "  'name',\n",
       "  'review_count',\n",
       "  'useful',\n",
       "  'user_id',\n",
       "  'yelping_since'},\n",
       " {'business_id', 'date', 'datetime'},\n",
       " {'business_id', 'compliment_count', 'date', 'text', 'user_id'},\n",
       " {'address',\n",
       "  'attributes',\n",
       "  'business_id',\n",
       "  'categories',\n",
       "  'city',\n",
       "  'hours',\n",
       "  'is_open',\n",
       "  'latitude',\n",
       "  'longitude',\n",
       "  'name',\n",
       "  'postal_code',\n",
       "  'review_count',\n",
       "  'stars',\n",
       "  'state'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ee017ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the common cols for join key\n",
    "\n",
    "table_col_dic = dict(zip(table_list_str, table_col_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb8476c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df_review': {'business_id',\n",
       "  'cool',\n",
       "  'date',\n",
       "  'funny',\n",
       "  'review_id',\n",
       "  'stars',\n",
       "  'text',\n",
       "  'useful',\n",
       "  'user_id'},\n",
       " 'df_user': {'average_stars',\n",
       "  'compliment_cool',\n",
       "  'compliment_cute',\n",
       "  'compliment_funny',\n",
       "  'compliment_hot',\n",
       "  'compliment_list',\n",
       "  'compliment_more',\n",
       "  'compliment_note',\n",
       "  'compliment_photos',\n",
       "  'compliment_plain',\n",
       "  'compliment_profile',\n",
       "  'compliment_writer',\n",
       "  'cool',\n",
       "  'elite',\n",
       "  'fans',\n",
       "  'friends',\n",
       "  'funny',\n",
       "  'name',\n",
       "  'review_count',\n",
       "  'useful',\n",
       "  'user_id',\n",
       "  'yelping_since'},\n",
       " 'df_checkin': {'business_id', 'date', 'datetime'},\n",
       " 'df_tip': {'business_id', 'compliment_count', 'date', 'text', 'user_id'},\n",
       " 'df_business': {'address',\n",
       "  'attributes',\n",
       "  'business_id',\n",
       "  'categories',\n",
       "  'city',\n",
       "  'hours',\n",
       "  'is_open',\n",
       "  'latitude',\n",
       "  'longitude',\n",
       "  'name',\n",
       "  'postal_code',\n",
       "  'review_count',\n",
       "  'stars',\n",
       "  'state'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_col_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab03a138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'date', 'stars', 'funny', 'useful', 'cool', 'review_id', 'business_id', 'user_id', 'text'}, {'average_stars', 'fans', 'name', 'compliment_profile', 'compliment_cool', 'compliment_note', 'elite', 'compliment_funny', 'friends', 'compliment_cute', 'review_count', 'yelping_since', 'compliment_list', 'useful', 'compliment_more', 'compliment_plain', 'compliment_writer', 'compliment_hot', 'cool', 'funny', 'compliment_photos', 'user_id'}, {'date', 'datetime', 'business_id'}, {'compliment_count', 'date', 'text', 'business_id', 'user_id'}, {'categories', 'longitude', 'name', 'attributes', 'postal_code', 'review_count', 'stars', 'city', 'address', 'state', 'hours', 'is_open', 'latitude', 'business_id'}])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_col_dic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f2727e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.intersection(*table_col_dic.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b328b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no common joykey in all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "982f54fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_review {'date', 'stars', 'funny', 'useful', 'cool', 'review_id', 'business_id', 'user_id', 'text'}\n",
      "df_checkin {'date', 'datetime', 'business_id'}\n",
      "df_tip {'compliment_count', 'date', 'text', 'business_id', 'user_id'}\n",
      "df_business {'categories', 'longitude', 'name', 'attributes', 'postal_code', 'review_count', 'stars', 'city', 'address', 'state', 'hours', 'is_open', 'latitude', 'business_id'}\n"
     ]
    }
   ],
   "source": [
    "for key,values in table_col_dic.items():\n",
    "    if 'business_id' in values:\n",
    "        print(key, values\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64aff6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# business_id_table = df_review.join(df_checkin.drop('date'), ['business_id'],'inner')\\\n",
    "#                                    .join(df_tip.drop('date'), ['business_id'],'inner')\\\n",
    "#                                    .join(df_business.drop('date'), ['business_id'],'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af0f0423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/12 22:08:07 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/12 22:08:22 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/12 22:08:37 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/12 22:08:52 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/12 22:09:07 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/12 22:09:22 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/12 22:09:37 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/12 22:09:52 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "23/03/12 22:10:07 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mbusiness_id_table\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcount\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:664\u001B[0m, in \u001B[0;36mDataFrame.count\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    654\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcount\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    655\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m    656\u001B[0m \n\u001B[1;32m    657\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    662\u001B[0m \u001B[38;5;124;03m    2\u001B[39;00m\n\u001B[1;32m    663\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 664\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcount\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1303\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1296\u001B[0m args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_args(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m   1298\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1299\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1300\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1301\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m-> 1303\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1304\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1305\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1307\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
      "File \u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1033\u001B[0m, in \u001B[0;36mGatewayClient.send_command\u001B[0;34m(self, command, retry, binary)\u001B[0m\n\u001B[1;32m   1031\u001B[0m connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_connection()\n\u001B[1;32m   1032\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1033\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m binary:\n\u001B[1;32m   1035\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_connection_guard(connection)\n",
      "File \u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1200\u001B[0m, in \u001B[0;36mGatewayConnection.send_command\u001B[0;34m(self, command)\u001B[0m\n\u001B[1;32m   1196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JNetworkError(\n\u001B[1;32m   1197\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError while sending\u001B[39m\u001B[38;5;124m\"\u001B[39m, e, proto\u001B[38;5;241m.\u001B[39mERROR_ON_SEND)\n\u001B[1;32m   1199\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1200\u001B[0m     answer \u001B[38;5;241m=\u001B[39m smart_decode(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m   1201\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnswer received: \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(answer))\n\u001B[1;32m   1202\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m answer\u001B[38;5;241m.\u001B[39mstartswith(proto\u001B[38;5;241m.\u001B[39mRETURN_MESSAGE):\n",
      "File \u001B[0;32m/opt/conda/miniconda3/lib/python3.8/socket.py:669\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    667\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    668\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 669\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    670\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    671\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# business_id_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aa38e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_id_table1 = df_review.join(df_checkin.drop('date'), ['business_id'],'inner')\n",
    "\n",
    "business_id_table2  =business_id_table1.join(df_tip.withColumnRenamed('text','tip_text').drop('date'), ['business_id','user_id'],'inner')\\\n",
    "                                   .join(df_business.withColumnRenamed('stars','business_stars').drop('date'), ['business_id'],'inner')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb16452-2958-4c3f-8200-9529fd74032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business_id',\n",
       " 'cool',\n",
       " 'date',\n",
       " 'date',\n",
       " 'datetime',\n",
       " 'funny',\n",
       " 'review_id',\n",
       " 'stars',\n",
       " 'text',\n",
       " 'useful',\n",
       " 'user_id']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(business_id_table1.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93d7b689-bc61-4396-9d99-00a2e2ea1bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_user.columns:\n",
    "    if i != 'user_id':\n",
    "        df_user = df_user.withColumnRenamed(i, \"user_{}\".format(i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b91e29e5-a4f8-4a1d-ad0b-1cb254c43414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_average_stars',\n",
       " 'user_compliment_cool',\n",
       " 'user_compliment_cute',\n",
       " 'user_compliment_funny',\n",
       " 'user_compliment_hot',\n",
       " 'user_compliment_list',\n",
       " 'user_compliment_more',\n",
       " 'user_compliment_note',\n",
       " 'user_compliment_photos',\n",
       " 'user_compliment_plain',\n",
       " 'user_compliment_profile',\n",
       " 'user_compliment_writer',\n",
       " 'user_cool',\n",
       " 'user_elite',\n",
       " 'user_fans',\n",
       " 'user_friends',\n",
       " 'user_funny',\n",
       " 'user_id',\n",
       " 'user_name',\n",
       " 'user_review_count',\n",
       " 'user_useful',\n",
       " 'user_yelping_since']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_user.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e49ec5c-4329-494f-87ca-4e27c4ca17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_id_table3 = business_id_table2.join(df_user, ['user_id'], 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3b28011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "business_id_table3.write.format('parquet').save('gs://data_set_connection/yelp_denormalized_try')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f858a-5a1d-4a99-813a-ab82fe993549",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet ,    avro "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
